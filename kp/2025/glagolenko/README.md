# Федеративное обучение на CIFAR-10

Данный проект реализует симуляцию клиент-серверной архитектуры для федеративного обучения с использованием алгоритма FedAvg (Federated Averaging). Система демонстрирует возможность эффективного обучения глобальной модели на распределенных данных при сохранении их локальности и конфиденциальности.

## Описание проекта

### Цель
Исследование, проектирование и программная реализация симуляции клиент-серверной архитектуры для федеративного обучения на датасете CIFAR-10.

### Основные компоненты

1. **Сервер (Центральный координатор)**
   - Инициализация глобальной модели
   - Координация раундов обучения
   - Агрегация результатов от клиентов
   - Сравнение с централизованным обучением

2. **Клиенты (Локальные агенты)**
   - Локальное обучение на своих данных
   - Отправка только обновлений модели (не данных)
   - Симуляция распределенных клиентов

3. **Алгоритм FedAvg**
   - Взвешенная агрегация параметров модели
   - Учет количества образцов у каждого клиента

## Технологический стек

- **Python 3.9+**
- **PyTorch 2.0+** - фреймворк для машинного обучения
- **Flask** - веб-сервер для API
- **Docker & Docker Compose** - контейнеризация
- **Matplotlib & Seaborn** - визуализация результатов
- **NumPy** - численные вычисления

## Архитектура системы

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Client 1      │    │   Client 2      │    │   Client N      │
│   (CIFAR-10     │    │   (CIFAR-10     │    │   (CIFAR-10     │
│    subset 1)    │    │    subset 2)    │    │    subset N)    │
└─────────┬───────┘    └─────────┬───────┘    └─────────┬───────┘
          │                      │                      │
          │ Model Updates        │ Model Updates        │ Model Updates
          │ (Weights only)       │ (Weights only)       │ (Weights only)
          │                      │                      │
          └──────────────────────┼──────────────────────┘
                                 │
                    ┌─────────────▼─────────────┐
                    │      Federated Server     │
                    │                           │
                    │  • Global Model           │
                    │  • FedAvg Aggregation     │
                    │  • Round Coordination     │
                    │  • Results Visualization  │
                    └───────────────────────────┘
```

## Логика работы сервисов

### Общий алгоритм федеративного обучения

1. **Инициализация**
   - Сервер создает глобальную модель CNN для CIFAR-10
   - Данные CIFAR-10 разделяются на 5 непересекающихся подмножеств
   - Каждый клиент получает свое подмножество данных

2. **Цикл обучения (10 раундов)**
   ```
   Для каждого раунда:
   ├── Сервер отправляет текущую глобальную модель всем клиентам
   ├── Каждый клиент:
   │   ├── Загружает глобальную модель
   │   ├── Обучает модель на своих локальных данных (3 эпохи)
   │   ├── Вычисляет обновления параметров
   │   └── Отправляет обновления на сервер
   ├── Сервер агрегирует обновления от всех клиентов (FedAvg)
   ├── Сервер обновляет глобальную модель
   └── Сервер оценивает модель на тестовых данных
   ```

3. **Сравнение с централизованным обучением**
   - Параллельно обучается централизованная модель на всех данных
   - Сравниваются метрики точности и потерь

### Детальная логика сервера

**Сервер (`server.py`)** - центральный координатор:

```python
class FederatedServer:
    def __init__(self):
        # Инициализация глобальной модели
        self.global_model = CIFAR10CNN()
        # Создание агрегатора FedAvg
        self.fedavg = FedAvg()
        # Загрузка тестовых данных для оценки
        self.test_dataset = get_cifar10_data()
    
    def get_global_model(self):
        # API endpoint: GET /get_model
        # Возвращает текущие параметры глобальной модели
    
    def receive_client_update(self, client_id, model_params, num_samples):
        # API endpoint: POST /send_update
        # Получает обновления от клиента и добавляет в агрегатор
    
    def aggregate_updates(self):
        # Агрегирует обновления от всех клиентов используя FedAvg
        # Обновляет глобальную модель
    
    def evaluate_global_model(self):
        # Оценивает модель на тестовых данных
        # Сохраняет метрики для визуализации
```

**Алгоритм FedAvg**:
```python
def aggregate(self):
    # Взвешенное усреднение параметров
    for layer in model_layers:
        aggregated_layer = 0
        for client_params, client_samples in zip(clients, sample_counts):
            weight = client_samples / total_samples
            aggregated_layer += weight * client_params[layer]
        final_params[layer] = aggregated_layer
```

### Детальная логика клиента

**Клиент (`client.py`)** - локальный агент:

```python
class FederatedClient:
    def __init__(self, client_id):
        # Инициализация локальной модели
        self.local_model = CIFAR10CNN()
        # Загрузка своего подмножества данных
        self.client_dataset = split_data_for_clients()[client_id]
        # Настройка оптимизатора
        self.optimizer = Adam(lr=0.001)
    
    def get_global_model(self):
        # Запрашивает глобальную модель с сервера
        # Загружает параметры в локальную модель
    
    def train_local_model(self, epochs=3):
        # Обучает локальную модель на своих данных
        for epoch in range(epochs):
            for batch in dataloader:
                optimizer.zero_grad()
                loss = criterion(model(batch), target)
                loss.backward()
                optimizer.step()
    
    def send_model_update(self):
        # Отправляет обновленные параметры на сервер
        # Передает только веса модели, не данные
```

### Протокол взаимодействия

1. **HTTP API** для связи сервер-клиент:
   - `GET /get_model` - получение глобальной модели
   - `POST /send_update` - отправка обновлений
   - `GET /status` - проверка статуса
   - `POST /start_training` - запуск обучения

2. **Сериализация моделей**:
   - Параметры модели конвертируются в JSON
   - Передаются только веса, не архитектура
   - Поддержка CPU и CUDA устройств

3. **Синхронизация**:
   - Клиенты ждут готовности сервера
   - Сервер ждет обновления от всех клиентов
   - Таймауты для предотвращения зависаний

### Разделение данных

```python
def split_data_for_clients(train_dataset, num_clients=5):
    # Стратифицированное разделение CIFAR-10
    # Каждый клиент получает ~10,000 образцов
    # Равномерное распределение классов
    # Непересекающиеся подмножества
```

### Визуализация результатов

1. **График точности**: Сравнение федеративной и централизованной моделей
2. **График потерь**: Динамика снижения функции потерь
3. **JSON метрики**: Детальные результаты для анализа

## Установка и запуск

### Требования

- Ubuntu 20.04 LTS
- Docker 20.10+
- Docker Compose 2.0+

### Шаг 1: Клонирование репозитория

```bash
git clone <repository-url>
cd federated-learning-cifar10
```

### Шаг 2: Создание необходимых директорий

```bash
mkdir -p shared results data
```

### Шаг 3: Запуск системы

```bash
# Быстрый запуск (рекомендуется)
./start.sh

# Или ручной запуск
docker-compose up -d --build

# Запуск с автоматическим мониторингом
python run_experiment.py
```

### Шаг 4: Мониторинг процесса

```bash
# Просмотр логов сервера
docker-compose logs -f federated-server

# Просмотр логов клиентов
docker-compose logs -f client-1
docker-compose logs -f client-2
# ... и так далее для всех клиентов

# Просмотр статуса всех сервисов
docker-compose ps
```

### Шаг 5: Проверка результатов

После завершения обучения результаты будут сохранены в директории `results/`:

- `federated_vs_centralized.png` - графики сравнения
- `training_results.json` - метрики в JSON формате

```bash
# Просмотр результатов
ls -la results/

# Просмотр метрик
cat results/training_results.json
```

## Структура проекта

```
federated-learning-cifar10/
├── docker-compose.yml          # Конфигурация Docker Compose
├── Dockerfile.server           # Dockerfile для сервера
├── Dockerfile.client           # Dockerfile для клиентов
├── requirements.txt            # Python зависимости
├── server.py                   # Серверная часть (центральный координатор)
├── client.py                   # Клиентская часть (локальные агенты)
├── run_experiment.py           # Скрипт автоматического запуска эксперимента
├── start.sh                    # Скрипт быстрого запуска
├── models/
│   ├── __init__.py
│   └── cnn_model.py           # CNN модель для CIFAR-10
├── federated_learning/
│   ├── __init__.py
│   └── fedavg.py              # Реализация алгоритма FedAvg
├── utils/
│   ├── __init__.py
│   └── data_utils.py          # Утилиты для работы с данными
├── shared/                     # Общие файлы между контейнерами
├── results/                    # Результаты обучения
├── data/                       # Данные CIFAR-10 (автоматически загружаются)
└── README.md                   # Документация
```

## API Endpoints

### Серверные endpoints

- `GET /get_model` - получение глобальной модели
- `POST /send_update` - отправка обновлений от клиента
- `GET /status` - статус сервера
- `POST /start_training` - запуск обучения

### Пример использования API

```bash
# Проверка статуса сервера
curl http://localhost:8000/status

# Получение глобальной модели
curl http://localhost:8000/get_model
```

## Результаты и визуализация

### График 1: Сравнение точности
- **Ось X**: Номер коммуникационного раунда/эпохи
- **Ось Y**: Точность (%)
- **Синяя линия**: Федеративная модель
- **Красная линия**: Централизованная модель

### График 2: Сравнение потерь
- **Ось X**: Номер коммуникационного раунда/эпохи
- **Ось Y**: Значение функции потерь
- **Синяя линия**: Федеративная модель
- **Красная линия**: Централизованная модель

## Параметры конфигурации

### Сервер
- Количество клиентов: 5
- Количество раундов: 10
- Устройство: CPU/CUDA (автоматически)

### Клиенты
- Локальные эпохи: 3
- Размер батча: 32
- Оптимизатор: Adam (lr=0.001)

### Модель
- Архитектура: CNN с 3 сверточными блоками
- Классы: 10 (CIFAR-10)
- Регуляризация: Dropout, BatchNorm

## Мониторинг и отладка

### Просмотр логов

```bash
# Все логи
docker-compose logs

# Конкретный сервис
docker-compose logs federated-server
docker-compose logs client-1

# Следить за логами в реальном времени
docker-compose logs -f
```

### Проверка состояния контейнеров

```bash
# Статус всех контейнеров
docker-compose ps

# Детальная информация
docker-compose top
```

### Остановка системы

```bash
# Остановка всех сервисов
docker-compose down

# Остановка с удалением volumes
docker-compose down -v
```

## Возможные проблемы и решения

### 1. Проблемы с памятью
```bash
# Увеличить лимиты памяти в docker-compose.yml
deploy:
  resources:
    limits:
      memory: 4G
```

### 2. Медленная загрузка данных
- Данные CIFAR-10 загружаются автоматически при первом запуске
- Для ускорения можно предварительно скачать данные

### 3. Проблемы с сетью
```bash
# Проверить сеть Docker
docker network ls
docker network inspect federated-learning-cifar10_federated-network
```

### 4. Очистка системы
```bash
# Удаление всех контейнеров и образов
docker-compose down --rmi all --volumes --remove-orphans

# Очистка Docker системы
docker system prune -a
```

## Расширение системы

### Добавление новых клиентов

1. Добавить новый сервис в `docker-compose.yml`:
```yaml
client-6:
  build:
    context: .
    dockerfile: Dockerfile.client
  container_name: client-6
  # ... остальная конфигурация
```

2. Обновить количество клиентов в `server.py`

### Изменение параметров обучения

Отредактировать соответствующие файлы:
- `server.py` - параметры сервера
- `client.py` - параметры клиентов
- `models/cnn_model.py` - архитектура модели

## Особенности реализации

### Безопасность и конфиденциальность
- **Никаких данных не передается** - только обновления параметров модели
- **Локальность данных** - каждый клиент работает только со своими данными
- **Сериализация весов** - передаются только численные параметры, не архитектура

### Масштабируемость
- **Docker контейнеризация** - легкое развертывание на любых системах
- **Горизонтальное масштабирование** - простое добавление новых клиентов
- **Автоматическая синхронизация** - сервер координирует всех клиентов

### Надежность
- **Таймауты и retry логика** - устойчивость к сетевым сбоям
- **Логирование** - детальное отслеживание процесса обучения
- **Graceful shutdown** - корректное завершение всех процессов

### Производительность
- **Параллельное обучение** - все клиенты работают одновременно
- **Эффективная агрегация** - оптимизированный алгоритм FedAvg
- **GPU поддержка** - автоматическое использование CUDA при наличии

## Ожидаемые результаты

### Метрики производительности
- **Федеративная модель**: ~75-80% точность на CIFAR-10 после 10 раундов
- **Централизованная модель**: ~80-85% точность для сравнения
- **Время обучения**: ~30-45 минут на CPU, ~15-20 минут на GPU

### Визуализация
- **График точности**: Показывает сходимость федеративной модели к централизованной
- **График потерь**: Демонстрирует эффективность обучения
- **JSON метрики**: Детальные данные для анализа

## Заключение

Данная система демонстрирует:

1. **Эффективность федеративного обучения** - модель обучается без передачи исходных данных
2. **Сохранение конфиденциальности** - передаются только обновления модели
3. **Масштабируемость** - легко добавлять новых клиентов
4. **Сравнимость результатов** - визуальное сравнение с централизованным подходом
5. **Практическая применимость** - готовое решение для исследований и экспериментов

Федеративная модель показывает сопоставимую точность с централизованной моделью, доказывая состоятельность подхода для распределенного машинного обучения с сохранением конфиденциальности данных.
